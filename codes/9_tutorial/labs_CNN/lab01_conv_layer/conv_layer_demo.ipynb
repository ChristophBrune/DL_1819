{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 10.01 : Convolutional layer - demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a convolutional module\n",
    "* inputs:  2 channels\n",
    "* output:  5 activation maps \n",
    "* filters are 3x3\n",
    "* padding with one layer of zero to not shrink anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = nn.Conv2d( 2 , 5 ,  kernel_size=3,  padding=1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make an input 2 x 6 x 6  (two channels, each one has 6 x 6 pixels )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.7181, 0.8568, 0.0340, 0.6575, 0.1105, 0.0676],\n",
      "          [0.1058, 0.9462, 0.6928, 0.1851, 0.8249, 0.6068],\n",
      "          [0.9668, 0.6312, 0.0397, 0.9596, 0.0154, 0.4954],\n",
      "          [0.6873, 0.5906, 0.5622, 0.7808, 0.4852, 0.7338],\n",
      "          [0.6976, 0.0188, 0.2101, 0.4038, 0.2028, 0.7788],\n",
      "          [0.6959, 0.1166, 0.3629, 0.0573, 0.1831, 0.6494]],\n",
      "\n",
      "         [[0.3348, 0.6391, 0.2354, 0.2884, 0.0911, 0.6898],\n",
      "          [0.4198, 0.0400, 0.3542, 0.9015, 0.3991, 0.0029],\n",
      "          [0.9608, 0.6041, 0.1153, 0.1647, 0.0654, 0.4545],\n",
      "          [0.6076, 0.9211, 0.8045, 0.4389, 0.9410, 0.3615],\n",
      "          [0.4944, 0.6257, 0.9751, 0.3753, 0.9210, 0.4607],\n",
      "          [0.2794, 0.3802, 0.0463, 0.6358, 0.4628, 0.6392]]]])\n"
     ]
    }
   ],
   "source": [
    "bs=1\n",
    "\n",
    "x=torch.rand(bs,2,6,6)\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed it to the convolutional layer: the output should have 5 channels (each one is 6x6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.0950, -0.0222,  0.2814,  0.1918,  0.1607,  0.1400],\n",
      "          [ 0.4557,  0.7871,  0.5395,  0.2820,  0.4214,  0.4022],\n",
      "          [ 0.1361,  0.5293,  0.7309,  0.5272,  0.7420,  0.4905],\n",
      "          [ 0.3607,  0.5200,  0.5835,  0.2141,  0.5204,  0.3304],\n",
      "          [ 0.2671,  0.6377,  0.3960,  0.5596,  0.4748,  0.4991],\n",
      "          [ 0.2439,  0.5019,  0.3449,  0.3135,  0.4734,  0.2963]],\n",
      "\n",
      "         [[-0.3155, -0.4418, -0.2179, -0.0805, -0.1021, -0.1605],\n",
      "          [-0.3865, -0.1475, -0.3887, -0.4216, -0.1672, -0.1586],\n",
      "          [-0.7149, -0.1579, -0.1094, -0.4234, -0.0819, -0.1469],\n",
      "          [-0.6867, -0.4072, -0.1451, -0.3148, -0.3689, -0.0114],\n",
      "          [-0.5861, -0.2939, -0.3605, -0.1900, -0.4118, -0.0066],\n",
      "          [-0.3493, -0.2604, -0.1719, -0.2952, -0.2374, -0.1628]],\n",
      "\n",
      "         [[-0.0399,  0.0976, -0.1810, -0.1335, -0.0367, -0.1062],\n",
      "          [ 0.1072, -0.0519,  0.0424,  0.1927, -0.0574,  0.0341],\n",
      "          [ 0.1835,  0.3113, -0.0952, -0.0150,  0.0540, -0.0502],\n",
      "          [ 0.2976,  0.0355,  0.1707,  0.2025, -0.0116,  0.1886],\n",
      "          [ 0.2766,  0.2274,  0.2726,  0.2923,  0.1661,  0.2263],\n",
      "          [ 0.1523, -0.0263,  0.1728,  0.0933,  0.2381,  0.2648]],\n",
      "\n",
      "         [[-0.1287, -0.2812,  0.1312, -0.1578, -0.2811, -0.0885],\n",
      "          [-0.0366, -0.0482, -0.5128, -0.0028, -0.3572, -0.1978],\n",
      "          [-0.0782, -0.1692, -0.5177, -0.4398,  0.0087, -0.2346],\n",
      "          [-0.0320, -0.3469, -0.4033, -0.1358, -0.5042, -0.2593],\n",
      "          [-0.2164, -0.5141, -0.4976, -0.3588, -0.6540, -0.2171],\n",
      "          [-0.2253, -0.6314, -0.3299, -0.4343, -0.4025, -0.2499]],\n",
      "\n",
      "         [[-0.1375,  0.1303, -0.4371, -0.0690,  0.0643, -0.0748],\n",
      "          [-0.0681, -0.3697, -0.0159, -0.1731, -0.5403, -0.1103],\n",
      "          [ 0.1231, -0.0551, -0.3976, -0.0929, -0.2519,  0.0272],\n",
      "          [-0.2414, -0.5490,  0.0439, -0.3474,  0.0271, -0.0783],\n",
      "          [-0.0532, -0.4258, -0.4479, -0.5236, -0.3317, -0.2226],\n",
      "          [-0.2835, -0.3516, -0.4658, -0.3322, -0.4764, -0.3850]]]],\n",
      "       grad_fn=<ThnnConv2DBackward>)\n"
     ]
    }
   ],
   "source": [
    "y=mod(x)\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets look at the 5 filters.\n",
    "* Our filters are 2x3x3\n",
    "* Each of the filter has 2 channels because the inputs have two channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[ 0.2357,  0.1336,  0.2168],\n",
       "          [ 0.1196,  0.0283,  0.1189],\n",
       "          [ 0.1463, -0.0218, -0.1337]],\n",
       "\n",
       "         [[ 0.0624,  0.0546,  0.0244],\n",
       "          [-0.0141, -0.1933, -0.0707],\n",
       "          [-0.0003,  0.1563, -0.1452]]],\n",
       "\n",
       "\n",
       "        [[[-0.0727, -0.0146, -0.0165],\n",
       "          [-0.0714, -0.1640, -0.0308],\n",
       "          [ 0.0509, -0.1349, -0.0065]],\n",
       "\n",
       "         [[ 0.0775, -0.0645, -0.0701],\n",
       "          [ 0.2238, -0.1962, -0.1409],\n",
       "          [ 0.1251,  0.1151, -0.1658]]],\n",
       "\n",
       "\n",
       "        [[[-0.0476,  0.2242,  0.1777],\n",
       "          [ 0.0165,  0.0593, -0.1151],\n",
       "          [-0.1122,  0.0237,  0.0610]],\n",
       "\n",
       "         [[-0.0220,  0.0428, -0.0252],\n",
       "          [ 0.1824,  0.1212,  0.0748],\n",
       "          [-0.0771, -0.0614, -0.0907]]],\n",
       "\n",
       "\n",
       "        [[[-0.2063,  0.1406,  0.0474],\n",
       "          [-0.0137,  0.0851,  0.1619],\n",
       "          [ 0.2096,  0.1427, -0.2184]],\n",
       "\n",
       "         [[ 0.0070, -0.1709, -0.2185],\n",
       "          [-0.0944, -0.1351,  0.0646],\n",
       "          [-0.2073,  0.0838, -0.0035]]],\n",
       "\n",
       "\n",
       "        [[[-0.0007, -0.1175,  0.2311],\n",
       "          [ 0.1150,  0.1670, -0.1737],\n",
       "          [-0.1287,  0.1487, -0.0227]],\n",
       "\n",
       "         [[-0.1113, -0.2275, -0.0234],\n",
       "          [-0.2204,  0.1443, -0.0241],\n",
       "          [ 0.1078,  0.1830, -0.1703]]]], requires_grad=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
